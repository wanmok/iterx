{"02567fd428a675ca91a0c6786f47f3e35881bcbd": [{"task": [["recognition"], ["semantic segmentation"], ["facial landmark detection"], ["classification"], ["age estimation"], ["multi - label classification"], ["human pose estimation"], ["image classification"], ["Head pose estimation"], ["age and head pose estimation"], ["Multi - label classification"], ["head pose estimation"], ["age"], ["facial key points detection"], ["Age estimation"], ["segmentation"], ["Label Ambiguity"], ["single - label recognition"], ["object detection"], ["Semantic segmentation"], ["face detection"], ["image classification tasks"], ["SLR"], ["least image classification"]], "metric": [["mAP"], ["accuracy"], ["accuracy rate"], ["average AP"], ["pose class classification accuracy"], ["MAE"], ["- error"], ["Acc"], ["Mean Absolute Error"]], "material": [["IF - VGG - \u21132"], ["PASCAL VOC dataset"], ["Pointing\u201904"], ["IF - VGG - KL"], ["AFLW"], ["VOC2011"], ["VOC2007"], ["ImageNet"], ["VOC2012"], ["PASCAL VOC2011 segmentation dataset"]], "method": [["IF - VGG - KL"], ["PF - DLDL"], ["DLDL"], ["VGG - Nets"], ["BFGS - LDL DLDL"], ["IF - DLDL"], ["DLDL - 8s"]], "incident_type": "material-method-metric-task"}, {"task": [["Multi - label classification"], ["single - label recognition"], ["age estimation"]], "incident_type": "material-method-metric-task"}]}
{"02b3d1d162080d9aefd3fc30a0bcc9a843073b5d": [{"task": [["large scale Language Modeling"], ["named entity recognition"], ["Language Modeling"], ["importance sampling"], ["Language Understanding"], ["IS"], ["Noise Contrastive Estimation"], ["language understanding"], ["fundamental language understanding"], ["perplexity"], ["NLP tasks"], ["inference"], ["language modeling"]], "material": [["1B Word Benchmark data set"], ["One Billion Word Benchmark data set"], ["IS"]], "metric": [["perplexity"], ["IS"]], "method": [["LSTM"], ["LSTM LMs"]], "incident_type": "material-method-metric-task"}]}
{"0398552184f80db111e9c28bf533b395f233ac00": [{"task": [["object detectors"], ["object detection"], ["detection"], ["Weakly - supervised object detection"], ["Object detection"], ["Bridging Saliency Detection"], ["Weakly Supervised Object Detection"], ["Saliency detection"], ["weakly supervised object detection"], ["saliency detection"]], "method": [["SPCL"], ["WOD"], ["LLO"]], "metric": [["OURS"], ["average precision"], ["AP score"], ["IOU"], ["AP"]], "material": [["WOD"], ["Pascal VOC 2007 test split"], ["VOC07 - Test"], ["Pascal VOC 2007 dataset"]], "incident_type": "material-method-metric-task"}]}
{"05d2700846c0323f79c1344aca5333994c7c03a5": [{"task": [["language modeling side"], ["connectionist temporal classification"], ["WER"], ["image classification"], ["ASR"], ["conversational speech recognition"]], "method": [["IBM 2016 English Conversational Telephone Speech Recognition System"]], "metric": [["word error rates"], ["CH"], ["accuracy"]], "material": [["SWB - 1"], ["Switchboard dataset"]], "incident_type": "material-method-metric-task"}]}
{"0626908dd710b91aece1a81f4ca0635f23fc47f3": [{"metric": [["top - error"], ["error"], ["top - 5 error"], ["top - 1 error"], ["accuracy"]], "method": [["GoogLeNet"], ["AlexNet"], ["Inception - v2"], ["Inception - v3"]], "task": [["single crop evaluation"], ["recognition"], ["dimension reduction"], ["ILSVR 2012 classification"], ["single frame evaluation"], ["Computer Vision"], ["ILSVRC classification challenge"], ["Inception"], ["classification"], ["computation"], ["post - classification of detection"], ["computer vision tasks"], ["computer vision solutions"]], "material": [["ImageNet ILSVRC 2012 classification benchmark"], ["ILSVRC 2012 classification challenge validation set"]], "incident_type": "material-method-metric-task"}]}
{"0678a8abea82793993cd89383319da75f6dc4be3": [{"method": [["ProNet"]], "material": [["COCO dataset"], ["PASCAL VOC data"], ["PASCAL VOC 2012"], ["MS COCO dataset"], ["COCO"], ["VOC 2012"], ["PASCAL VOC 2012 dataset"], ["MS COCO datasets"], ["VOC 2012 dataset"], ["PASCAL VOC 2012 validation set"]], "task": [["image - level annotations"], ["multi - class classification"], ["pose estimation"], ["Object classification"], ["object classification"], ["localization"], ["object detection"], ["semantic segmentation"], ["image classification"], ["segmentation"], ["face detection"], ["classification"], ["image classification task"], ["simultaneous object classification"], ["point - based localization tasks"]], "metric": [["mAP"], ["image - level score"], ["proposal score"], ["accuracy"]], "incident_type": "material-method-metric-task"}]}
{"081531984770a74e87dbd68907061b4b0f3631bf": [{"task": [["SR task"], ["classification"], ["video classification"], ["Motion Compensation"], ["image classification"], ["image SR"], ["real - time image SR"], ["motion compensated video SR"], ["Video SR"], ["SR"], ["video SR"], ["face recognition"], ["Image and video SR"], ["SR problem"], ["view synthesis"], ["single image SR"], ["Real - Time Video Super - Resolution"], ["multi - image SR"], ["image super - resolution"]], "method": [["S5 - SW"], ["ESPCN"], ["VSRnet"], ["VESPCN"]], "metric": [["MOVIE index"], ["reconstruction accuracy"], ["accuracy"]], "material": [["CDVL dataset"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}, {"task": [["SR"], ["video SR"]], "incident_type": "material-method-metric-task"}]}
{"0834e74304b547c9354b6d7da6fa78ef47a48fa8": [{"method": [["LINE"], ["LINE - SGD"], ["DeepWalk"]], "material": [["LINE"], ["IsoMap"]], "task": [["LINE"], ["classification"]], "metric": [["AAAI"]], "incident_type": "material-method-metric-task"}, {"method": [["LINE"], ["LINE - SGD"], ["DeepWalk"]], "material": [["LINE"], ["IsoMap"]], "task": [["LINE"], ["classification"]], "metric": [["AAAI"]], "incident_type": "material-method-metric-task"}]}
{"0a3381f0432c5cfe491c718349d7a44e5814592c": [{"task": [["grammatical error detection"], ["Error Detection"], ["speech recognition"], ["detection"], ["error correction"], ["grammatical error correction"], ["error detection"], ["assessment"]], "metric": [["CUUI"], ["essay score"]], "method": [["Bi - LSTM"]], "material": [["IELTS examination dataset"], ["NUCLE dataset"], ["P1"]], "incident_type": "material-method-metric-task"}]}
{"0a6c36de8726b6feaab586046ddc1d1a008f44f9": [{"method": [["KITTI"], ["HOG + LUV"]], "material": [["Katamari"], ["ACF"], ["KITTI"]], "task": [["Pedestrian detection"], ["Pedestrian Detection"], ["generic object detection"], ["object detection"], ["detection"], ["image classification"], ["pedestrian detection"], ["2Ped detection"], ["pedestrian detectors"]], "metric": [["ACF"], ["minimum miss - rate"]], "incident_type": "material-method-metric-task"}, {"task": [["pedestrian detection"], ["Pedestrian detection"], ["detection"]], "incident_type": "material-method-metric-task"}]}
{"0c47cad9729c38d9db1f75491b1ee4bd883a5d4e": [{"metric": [["EMA"], ["train accuracy"], ["dev set accuracy"], ["accuracy"]], "material": [["CIFAR - 10"], ["semi - supervised CIFAR - 10"], ["IWSLT 2015"], ["CVT accuracy"]], "task": [["Named Entity Recognition"], ["translation"], ["image recognition"], ["semi - supervised text classification"], ["machine translation"], ["Semi - Supervised Sequence Modeling"]], "method": [["Cross - View Training"], ["Multi - View Learning"], ["CVT"]], "incident_type": "material-method-metric-task"}]}
{"0dc9eb7d17f2def56ad930945f2521653f04c3fa": [{"method": [["SNM5"], ["SNM10 - skip"], ["SNM"], ["Kneser - Ney"], ["SNM5 - skip"], ["SNM10"]], "material": [["SNM5 - skip"]], "incident_type": "material-method-metric-task"}, {"method": [["SNM5"], ["SNM10 - skip"], ["SNM"], ["Kneser - Ney"], ["SNM5 - skip"]], "material": [["SNM5 - skip"]], "incident_type": "material-method-metric-task"}]}
{"107010b7f2abe3c0c9df62bcef35eb77f6fc76df": [{"method": [["PAD of DANN"], ["DANN"]], "metric": [["accuracy"]], "task": [["representation learning approach"]], "incident_type": "material-method-metric-task"}]}
{"1130d8fdd931225c2d7563c3808367726cfa1c3a": [{"metric": [["test error"], ["NORB datasets"], ["error rate"]], "method": [["PixelGAN"], ["PixelCNN"], ["SVHN"], ["PixelGAN Autoencoders"], ["DiscoGAN"], ["GAN"]], "material": [["MNIST"], ["MNIST Dataset"], ["SVHN"], ["SVHN Dataset"], ["NORB datasets"]], "task": [["semi - supervised classification tasks"], ["semi - supervised classification"], ["classification"]], "incident_type": "material-method-metric-task"}]}
{"11356cd6bb0f2776a88cd584ff108470414c6594": [{"method": [["SC"], ["ResNet networks"], ["OctNets"], ["OctNet"], ["VGG - A"], ["oct - trees"], ["VGG networks"], ["VSC"], ["ModelNet"], ["Submanifold Sparse Convolutional Networks"], ["Convolutional networks"]], "metric": [["AP"], ["error"], ["accuracy"]], "task": [["image classification"]], "material": [["ModelNet - 40"], ["CASIA dataset"], ["CASIA"], ["SC"]], "incident_type": "material-method-metric-task"}]}
{"11da0c54ba904a1cb31a09d10da55f73e8825c61": [{"method": [["TBCNN"], ["NLI"]], "task": [["natural language inference"], ["matching the subject and object"], ["Natural Language Inference"], ["Recognizing entailment and contradiction"], ["natural language understanding"], ["two - layer subtree feature detectors"], ["prediction"], ["sentence matching"], ["NLI task"], ["sentence pair modeling"], ["matching"], ["entailment and contradiction"], ["NLI"], ["semantic compositionality"], ["sentence modeling"], ["word analogy task"], ["Entailment recognition"], ["inference"], ["relation classification"]], "material": [["SNLI"], ["NLI"], ["Arc - II"], ["AAAI"], ["NIPS"]], "metric": [["accuracy"]], "incident_type": "material-method-metric-task"}]}
{"1235dd37312cb20aced0e97d953f6379d8a0c7d4": [{"method": [["V - LSTM"], ["V - BiMPM"], ["SNLI"], ["VQA"], ["V - SNLI"]], "metric": [["accuracy"]], "task": [["TE task"], ["Textual Entailment task"], ["Grounded Textual Entailment"], ["GTE task"]], "material": [["snli"], ["SNLI"], ["Flickr30 K dataset"], ["V - SNLI"]], "incident_type": "material-method-metric-task"}, {"metric": [["accuracy"]], "material": [["snli"], ["SNLI"]], "method": [["V - LSTM"], ["V - BiMPM"], ["V - SNLI"], ["VQA"]], "task": [["Textual Entailment task"], ["TE task"], ["GTE task"]], "incident_type": "material-method-metric-task"}]}
{"14318685b5959b51d0f1e3db34643eb2855dc6d9": [{"metric": [["accuracy"], ["top - 1 accuracy rate"], ["error"], ["top - 1 accuracy"], ["top - 5 error rate"], ["top - 1 error rate"], ["mAP"]], "method": [["GoogLeNet"], ["ImageNet Large - Scale Visual Recognition Challenge 2014"]], "material": [["ILSVRC\u00e2\u0080\u009914"]], "task": [["human pose estimation"], ["object detection"], ["image classification literature"], ["detection"], ["classifier"], ["detection task"], ["object - detection"], ["classification"], ["ILSVRC 2014 classification"], ["ImageNet classification challenge"], ["image recognition"]], "incident_type": "material-method-metric-task"}]}
{"16051bbe3a7f7c77a952ebf76722ea655e8906ca": [{"task": [["ANR"], ["single image super - resolution"], ["Image Super - Resolution"], ["single image superresolution"], ["Image Super - resolution"], ["SISR"], ["SR"], ["image classification"], ["SR reconstruction"], ["Image SR"], ["image degradation"], ["image super - resolution approaches"], ["image super - resolution"]], "method": [["FARF"]], "material": [["SAI"], ["A +"], ["ARF"], ["Set14"], ["ITQ"]], "metric": [["reconstruction error"], ["prediction accuracy"], ["accuracy"]], "incident_type": "material-method-metric-task"}]}
{"160563abbd75265b19afc8b4169bab9e1eb33d97": [{"metric": [["accuracy"], ["error"], ["error rate"]], "material": [["English"], ["WMT 2014 test set"], ["NLI"], ["Amharic"], ["Swahili"], ["English XNLI"], ["OPUS"], ["XNLI"], ["BUCC dataset"], ["Tatoeba dataset"], ["MLDoc dataset"]], "task": [["zero - shot cross - lingual natural language inference"], ["cross - lingual document classification"], ["Zero - Shot Cross - Lingual Transfer"], ["classifier"], ["classification"], ["Natural Language Inference"], ["cross - lingual classification"]], "method": [["Tatoeba"], ["XNLI"], ["MultiNLI"], ["NLI"]], "incident_type": "material-method-metric-task"}]}
{"175f74a09241b6cb5101a2a09978095720db7d5f": [{"metric": [["restoration accuracy"], ["validation accuracy"], ["mean square error"], ["mean squared reconstruction error"], ["accuracy"]], "task": [["compact RNN view"], ["residual SR"], ["single - image super - resolution"], ["single image SR"], ["Image Super - Resolution"], ["EDSR"], ["SR"], ["image SR"], ["image super - resolution"]], "material": [["DIV2 K dataset"], ["Set14"], ["Peak Signal - to - Noise Ratio"]], "method": [["DSRN"], ["DenseNet"]], "incident_type": "material-method-metric-task"}]}
{"1778e32c18bd611169e64c1805a51abff341ca53": [{"task": [["natural language understanding"], ["natural language inference"], ["attention"], ["NLI"], ["sentence understanding"], ["paraphrase identification"], ["computation"], ["Natural Language Inference"], ["natural language inference task"], ["image recognition"], ["NLI task"], ["Quora Question Pair dataset"]], "metric": [["mismatched score"], ["PARAPHRASE"], ["error reduction"], ["ensemble score"], ["in - domain development accuracy"], ["matched score"], ["Matched validation score"], ["accuracy"]], "material": [["SNLI"], ["PARAPHRASE"], ["Quora Question Pair dataset"], ["Quora Question Pair Dataset"], ["large scale NLI"], ["IIN"]], "method": [["Multi - Genre NLI"], ["DIIN"], ["NLI"], ["Densely Interactive Inference Network"], ["Interactive Inference Network"], ["MultiNLI"], ["IIN"]], "incident_type": "material-method-metric-task"}]}
{"178275dbdcfa267e41a9d5efe386ee5874c6d23f": [{"task": [["prediction"], ["image captioning task"]], "method": [["fraternal dropout"], ["Fraternal Dropout"]], "metric": [["averaged prediction score"]], "material": [["CIFAR - 10 dataset"], ["Wikitext - 2"], ["Fraternal dropout"], ["WT2"], ["CIFAR - 10"], ["Word level WikiText - 2"], ["PTB dataset"]], "incident_type": "material-method-metric-task"}]}
{"178631e0f0e624b1607c7a7a2507ed30d4e83a42": [{"metric": [["test set error"], ["phoneme error rate"], ["error rate"]], "task": [["weight noise"], ["speech recognition"], ["TIMIT"], ["Phoneme recognition"], ["large vocabulary speech recognition"], ["segmentation"], ["Speech Recognition"], ["phoneme recognition"], ["cursive handwriting recognition"]], "method": [["Recurrent Neural Networks"], ["CTC"]], "material": [["TIMIT"]], "incident_type": "material-method-metric-task"}]}
{"18168aea48a22f6fe2fe407c0ff70083cba225a7": [{"task": [["super - resolution"], ["inpainting"], ["image or video super - resolution"], ["image denoising"], ["image restoration"], ["Image super - resolution"], ["semantic segmentation"], ["Image Restoration"], ["image recognition"]], "material": [["Set5"], ["Set14"], ["Berkeley Segmentation Dataset"], ["BSD200 dataset"]], "metric": [["accuracy"]], "incident_type": "material-method-metric-task"}]}
{"193089d56758ab88391d846edd08d359b1f9a863": [{"metric": [["accuracy"], ["competitive accuracy"], ["rank - 1 accuracy"], ["rank - 1"], ["rank1 accuracy"], ["mean image size"], ["average rank - 1 accuracy"], ["re - ID accuracy"], ["mAP"]], "task": [["person re - ID"], ["person re - identification"], ["re - identification"], ["identification"], ["public person re - ID"], ["image retrieval"], ["face identification"], ["similarity estimation"], ["signature verification"], ["Person Re - identification"], ["Large - scale Person Re - identification"], ["face recognition"], ["single - shot setting"], ["large - scale person re - identification"], ["re - ID"], ["Person re - identification"], ["similarity measurement"]], "material": [["CUHK03"], ["Market - 1501"], ["Market1501 + 500k"], ["Market1501 dataset"], ["Market1501"]], "method": [["DeepID"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["public person re - ID"], ["face identification"], ["Person Re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - ID"], ["person re - identification"], ["Large - scale Person Re - identification"], ["re - ID"], ["Person re - identification"]], "incident_type": "material-method-metric-task"}]}
{"193b518bc3025804c6d587c74cbc154d91478417": [{"task": [["adapted segmentation"], ["Semantic segmentation"], ["semantic segmentation"], ["segmentation"], ["image classification"], ["segmentations"], ["pixel - level prediction tasks"], ["pixel - level semantic segmentation"], ["semantic segmentations"], ["Semantic Segmentation"]], "material": [["Cityscapes validation set"], ["Cross - City dataset"], ["GTA5 dataset"], ["Cityscapes dataset"], ["ImageNet"], ["SYNTHIA"], ["IoU"], ["Cityscapes"], ["CyCADA"], ["SYNTHIA - RAND - CITYSCAPES set"]], "metric": [["segmentation accuracy"], ["accuracy"]], "incident_type": "material-method-metric-task"}]}
{"1d0dcb458aa4d30b51f7c74b159be687f39120a0": [{"task": [["pose estimation"], ["multi - class person identification"], ["person re - identification"], ["ReID"], ["pose detector"], ["Person Re - Identification"], ["Person Re - identification"], ["segmentation"], ["person Re - Identification"], ["person ReID"], ["Person ReID"]], "method": [["VIPeR"], ["PDC"], ["Pose - driven Deep Convolutional Model"]], "metric": [["mAP"], ["rank1 accuracy"], ["Market 1501"], ["rank20 accuracy"], ["accuracy"]], "material": [["Market 1501"], ["Market - 1501"], ["Market1501"], ["CUHK 03"]], "incident_type": "material-method-metric-task"}, {"task": [["person re - identification"], ["ReID"], ["Person Re - Identification"], ["Person Re - identification"], ["person Re - Identification"], ["person ReID"]], "incident_type": "material-method-metric-task"}]}
{"1f08598381af9146d0fd9a61b30d0e51a7331689": [{"method": [["Ape - X DPG"], ["Ape - X DQN"], ["Ape - X"], ["Prioritized DQN"]], "metric": [["absolute TD error"], ["TD error"]], "material": [["Atari"]], "incident_type": "material-method-metric-task"}]}
{"2138a7127429d67746ec78de46d6820fee0e548e": [{"method": [["Graph2Seq - MA - B"], ["Seq2Seq"], ["GCN"], ["SP - S"], ["Graph2Seq - MA - F"], ["Graph2Seq - NGE"], ["Graph2Seq"], ["Graph2Seq - MA"]], "metric": [["BLEU - 4 score"], ["hop size"], ["execution accuracy"], ["accuracy"]], "material": [["Set2Seq"], ["WikiSQL dataset"], ["Seq2Seq"], ["Graph2Seq"]], "task": [["Natural Language Generation tasks"], ["Seq2Seq"], ["graph - to - sequence tasks"]], "incident_type": "material-method-metric-task"}]}
{"21a1654b856cf0c64e60e58258669b374cb05539": [{"task": [["grasp detection"], ["real - time detectors"], ["single object detection"], ["object detection"], ["real - time detection"], ["detections"], ["detection"], ["fast object detection"], ["image classification"], ["prediction"], ["person detection"], ["Real - Time Object Detection"], ["real - time object detection"], ["Object detection"], ["Unified Detection"], ["Person Detection"], ["Real - Time Detection"]], "metric": [["AP"], ["accuracy"], ["VOC 2007 data"], ["mAP"]], "method": [["Fast YOLO"], ["YOLO model"], ["Fast R - CNN"], ["YOLO"], ["R - CNN"]], "material": [["Pascal VOC 2007"], ["VOC 2007"], ["People - Art Dataset"], ["VOC 2012 test set"], ["IOU"], ["YOLO"], ["VOC 2012"], ["VOC 2007 test set"], ["Picasso Dataset"]], "incident_type": "material-method-metric-task"}, {"task": [["object detection"], ["real - time detection"], ["detection"], ["image classification"], ["person detection"], ["real - time object detection"], ["Person Detection"], ["Real - Time Detection"]], "incident_type": "material-method-metric-task"}]}
{"232b43584b2236669c0a53702ad89ab10c3886ea": [{"material": [["Atari - 57"], ["Atari - 57 benchmark"], ["Atari 2600 games"], ["UVFA"], ["Atari games"]], "method": [["IQN"], ["QR - DQN"]], "task": [["risk - averse policies"], ["IQN"], ["DQN"], ["RL"]], "incident_type": "material-method-metric-task"}]}
{"23d2d3a6ffebfecaa8930307fdcf451c147757c8": [{"task": [["real - world problems"], ["text generation scenarios"], ["SS"], ["classification"], ["human judgement"], ["machine translation"]], "method": [["SeqGAN"], ["GAN"]], "metric": [["average score"], ["BLEU score"], ["BLEU"], ["mean squared error"]], "material": [["SeqGAN"]], "incident_type": "material-method-metric-task"}]}
{"24730424236724d3f798dec02901e7a1f1c4710e": [{"method": [["JMPF"]], "task": [["single - image super - resolution"], ["Image Super - Resolution"], ["Image super - resolution"], ["SR"], ["image SR"], ["classification"], ["image super - resolution"]], "metric": [["average error"], ["accuracy"]], "material": [["A +"]], "incident_type": "material-method-metric-task"}, {"task": [["single - image super - resolution"], ["Image Super - Resolution"], ["Image super - resolution"], ["SR"], ["image SR"], ["classification"], ["image super - resolution"]], "metric": [["accuracy"]], "method": [["JMPF"]], "incident_type": "material-method-metric-task"}]}
{"249b3b7421d3cdb932eecfe4b67203e0e46806b2": [{"method": [["SST - 2"], ["SNLI"], ["SST"], ["Cell - aware Stacked LSTM"], ["LSTM"], ["Cell - aware Stacked LSTMs"], ["SST - 5"], ["CAS - LSTM"], ["stacked LSTM"], ["Highway LSTMs"], ["Tree - LSTMs"]], "task": [["natural language inference"], ["Paraphrase Identification"], ["sentence pair classification"], ["text classification"], ["MLP classifier"], ["language modeling"], ["modeling sentences"], ["NLI task"], ["NLI"], ["paraphrase identification"], ["Sentiment Classification"], ["PI task"], ["NLP tasks"], ["paraphrase detection"], ["sentence modeling"], ["sentiment classification"], ["Modeling Sentences"], ["5 - class classification problem"], ["MultiNLI"], ["computation"]], "material": [["SST - 5 setting"], ["SNLI"], ["SST - 2"], ["Quora Question Pairs datasets"], ["Quora Question Pairs dataset"], ["SST - 5"]], "metric": [["competitive accuracy"], ["accuracy"]], "incident_type": "material-method-metric-task"}, {"task": [["sentiment classification"], ["natural language inference"], ["paraphrase identification"], ["NLI"]], "metric": [["accuracy"]], "material": [["SNLI"]], "incident_type": "material-method-metric-task"}]}
{"25a784f7f8c94c42821ee078587fc38dffcd00a4": [{"task": [["Face detection"], ["object detection"], ["face detector"], ["robust face detector"], ["face detectors"], ["detection"], ["image classification"], ["Robust Face Detection"], ["face detection"], ["classification"], ["classification loss"], ["human - level detection"]], "material": [["WIDER FACE val dataset"], ["WIDER FACE"], ["FACE"], ["AFW dataset"], ["Pascal VOC dataset"], ["AFW datasets"], ["SNIP"], ["IoU"], ["WPAS"], ["SSH"], ["WIDER FACE dataset"], ["WIDER FACE train set"]], "method": [["WIDER FACE"], ["S FD"], ["PyramidBox"], ["VGG16"]], "metric": [["AP"], ["AP=99.0"], ["APs"]], "incident_type": "material-method-metric-task"}]}
{"25f5df29342a04936ba0d308b4d1b8245a7e8f5c": [{"metric": [["precision accuracy"], ["PCKh - 0.5 score"], ["accuracy"]], "task": [["pose estimation"], ["articulated pose estimation"], ["part detection"], ["graphical model - style inference"], ["message passing inference"]], "material": [["MPI dataset"], ["Leeds Sports Pose"], ["FLIC dataset"], ["FLIC datasets"], ["LSP dataset"], ["FLIC Dataset"], ["MPII Human Pose dataset"], ["MPII datasets"], ["MPII Human Pose Dataset"]], "incident_type": "material-method-metric-task"}]}
{"269730dbbabed8b8b5ba720e44a4c31b1f51e8f1": [{"method": [["Query - Reduction Network 1"], ["QRN"]], "metric": [["average accuracy"], ["bAbI QA dataset error rates"], ["accuracy"]], "task": [["QUESTION ANSWERING"], ["question answering"], ["QA"]], "material": [["DSTC2 dataset"], ["bAbI QA"], ["bAbI story - based QA 1k"]], "incident_type": "material-method-metric-task"}, {"metric": [["average accuracy"]], "task": [["QA"], ["question answering"]], "incident_type": "material-method-metric-task"}]}
{"270e65acc071b9e4e2a632720130c0e10cb6fa08": [{"method": [["NTI - SLSTM"], ["NTI - ANF - LSTM"], ["NTI"], ["Neural Tree Indexers"], ["S - LSTM"], ["NTI - SLSTM - LSTM"], ["NTI - SLSTMs"], ["NTI model"]], "task": [["Answer Sentence Selection"], ["neural machine translation"], ["sentence classification"], ["classification"], ["NLP tasks"], ["tree attention"], ["Text Understanding"]], "metric": [["MAP"], ["attention score"], ["accuracy"]], "material": [["SNLI"], ["WikiQA dataset"]], "incident_type": "material-method-metric-task"}]}
{"2777cd26b2c257843273fe41ad4c5b8cdf1b1b75": [{"method": [["NAN"]], "metric": [["F score"], ["accuracy"]], "material": [["PASCAL - VOC - 2010 dataset"], ["PASCAL - Person - Part benchmark datasets"], ["MHP v1.0"], ["MHP v2.0 dataset"], ["MHP v1.0 dataset"], ["MHP"], ["MHP v2.0"]], "task": [["NAN"], ["multi - human parsing"], ["human - centric analysis"], ["instance segmentation"], ["semantic saliency prediction"]], "incident_type": "material-method-metric-task"}]}
{"27a99c21a1324f087b2f144adc119f04137dfd87": [{"metric": [["error"], ["error rate"], ["top - 1 error"], ["prediction accuracy"], ["accuracy"]], "material": [["MNIST"], ["ILSVRC - 2012 validation set"], ["ImageNet"], ["ImageNet datasets"], ["top - 1"], ["MNIST dataset"], ["ImageNet ILSVRC - 2012 dataset"], ["SVD - half"]], "task": [["computation"]], "incident_type": "material-method-metric-task"}]}
{"27aa0f3ec934925265f93fac7ff1cd1d70ceb618": [{"material": [["Amazon Reviews dataset"], ["SANCL 2012 shared task dataset"], ["POS"]], "method": [["NLP Neural networks"], ["MT - Tri"]], "task": [["sentiment analysis"], ["NLP tasks"], ["tagging"], ["Sentiment analysis"]], "metric": [["average accuracy"], ["mean accuracy"], ["Accuracy"], ["OOV accuracy"], ["accuracy"]], "incident_type": "material-method-metric-task"}, {"task": [["sentiment analysis"], ["tagging"]], "incident_type": "material-method-metric-task"}]}
{"2a86bcdfb1d817ddb76ba202319f8267a36c0f62": [{"task": [["instance classification"], ["object detection"], ["proposal classification"], ["bag classification"], ["detection"], ["image classification"], ["WSOD"], ["object recognition"], ["classification"], ["Weakly Supervised Object Detection"], ["Object detection"], ["fully supervised object detection"]], "metric": [["cluster score"], ["image score"], ["cluster center confidence score"], ["proposal confidence score"], ["cluster confidence score"], ["IoU"], ["localization accuracy"], ["confidence score"], ["AP"], ["PASCAL criterion"], ["Average Precision"], ["mAP"]], "material": [["AP"], ["PASCAL VOC dataset"], ["PASCAL VOC"], ["MS - COCO dataset"], ["MS - COCO datasets"], ["PASCAL VOC 2012"], ["MS - COCO"], ["VOC 2007 dataset"], ["ImageNet"], ["ImageNet detection dataset"], ["WSOD"], ["IoU"], ["PASCAL VOC 2007"]], "method": [["ImageNet"], ["WSOD"], ["PASCAL VOC"]], "incident_type": "material-method-metric-task"}, {"task": [["instance classification"], ["object detection"], ["proposal classification"], ["bag classification"], ["detection"], ["image classification"], ["WSOD"], ["classification"], ["Weakly Supervised Object Detection"], ["Object detection"]], "metric": [["AP"], ["image score"]], "material": [["PASCAL VOC dataset"], ["MS - COCO dataset"], ["MS - COCO datasets"], ["PASCAL VOC 2012"], ["MS - COCO"], ["IoU"], ["PASCAL VOC 2007"]], "incident_type": "material-method-metric-task"}]}
{"2f04ba0f74df046b0080ca78e56898bd4847898b": [{"task": [["Face detection"], ["multi - view face detector"], ["multi - view detection"], ["Human face detection"], ["face detector"], ["face detectors"], ["detection"], ["multi - view face detection"], ["pedestrian detection"], ["face detection"], ["classification"], ["Multi - view Face Detection"], ["real - time face detection"], ["face detection domain"]], "metric": [["discrete score"], ["true positive rate"], ["accuracy"]], "material": [["AFW"], ["Google Picasa"], ["FPS"], ["PASCAL VOC"]], "method": [["FDDB"]], "incident_type": "material-method-metric-task"}, {"task": [["Face detection"], ["multi - view detection"], ["face detector"], ["multi - view face detection"], ["face detection"]], "incident_type": "material-method-metric-task"}]}
{"2f56b1ac5b9faac9527b6814778925e9242cf5fd": [{"method": [["OHEM"], ["Fast R - CNN"], ["MR - CNN"]], "metric": [["accuracy"], ["AP"], ["object detection accuracy"], ["mAP"]], "task": [["image descriptors"], ["Image classification"], ["Region - based Object Detectors"], ["ImageNet classification"], ["object detection"], ["detection"], ["ImageNet detection"], ["image classification"], ["pedestrian detection"], ["object detectors"], ["Object detection"], ["ConvNet - based object detection"]], "material": [["VOC07 data"], ["MS COCO dataset"], ["VOC07"], ["PASCAL VOC07 dataset"], ["MS COCO"], ["VOC 2007"], ["2012"], ["IoU"], ["OHEM"], ["VOC 2012"], ["PASCAL VOC 2007"]], "incident_type": "material-method-metric-task"}]}
{"2f97ee95cad6a1f13596b108072b846c6f747d4e": [{"method": [["Microsoft 2016 Conversational Speech Recognition System"]], "material": [["NIST 2000 CTS test set"], ["RT - 02 Switchboard set"], ["NIST 2002 CTS test set"], ["NIST 2000 Switchboard set"], ["CNTK"], ["English CTS"]], "task": [["search procedure"], ["speech recognition"], ["Conversational speech recognition"], ["speech recognition task"], ["tuning"], ["Switchboard recognition task"], ["conversational telephone speech recognition"], ["image recognition"], ["noise - contrastive estimation"]], "metric": [["word error rate"], ["model accuracy"], ["error rate"], ["out - of - domain data"], ["accuracy"]], "incident_type": "material-method-metric-task"}]}
{"322a7dad274f440a92548faa8f2b2be666b2d01f": [{"material": [["ADE20 K data"], ["ImageNet scene parsing challenge 2016"], ["PASCAL VOC"], ["Mean IoU"], ["MS - COCO dataset"], ["PASCAL VOC 2012"], ["MS - COCO"], ["OpenMPI"], ["ImageNet"], ["ADE20 K dataset"], ["PASCAL VOC 2012 segmentation dataset"], ["VOC 2012 data"], ["ADE20K."], ["Cityscapes"], ["ADE20 K"]], "method": [["ResNet"], ["FCN"], ["Pyramid Scene Parsing Network"], ["ResNet - based FCN"], ["PSPNet"]], "metric": [["mIoU accuracy"], ["accuracy"]], "task": [["PASCAL VOC semantic segmentation"], ["scene / image classification"], ["pixel - level prediction"], ["semantic segmentation tasks"], ["scene parsing"], ["segmentation"], ["semantic segmentation"], ["image classification"], ["classification"], ["scene parsing task"], ["PASCAL VOC 2012 semantic segmentation"]], "incident_type": "material-method-metric-task"}, {"material": [["PASCAL VOC"], ["ImageNet scene parsing challenge 2016"], ["MS - COCO dataset"], ["PASCAL VOC 2012"], ["OpenMPI"], ["ImageNet"], ["ADE20 K dataset"], ["PASCAL VOC 2012 segmentation dataset"], ["Cityscapes"], ["ADE20 K"]], "task": [["PASCAL VOC semantic segmentation"], ["scene / image classification"], ["pixel - level prediction"], ["semantic segmentation tasks"], ["scene parsing"], ["semantic segmentation"], ["image classification"], ["segmentation"], ["classification"], ["scene parsing task"], ["PASCAL VOC 2012 semantic segmentation"]], "method": [["Pyramid Scene Parsing Network"], ["PSPNet"]], "metric": [["mIoU accuracy"], ["accuracy"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}, {"task": [["scene parsing"], ["semantic segmentation"], ["image classification"], ["scene / image classification"]], "incident_type": "material-method-metric-task"}]}
{"325af39d281d5903a269c01fab8f53d7400a4c49": [{"metric": [["AP evaluation measure"], ["AP"], ["accuracy"]], "material": [["WAF datasets"], ["MPII Human Pose"], ["WAF"], ["MPII Multi - Person dataset"], ["MPII Human Pose dataset"], ["MPII Video Pose \u201d dataset"], ["AP"]], "task": [["pose estimation"], ["ArtTrack"], ["single - frame pose estimation"], ["graph partitioning"], ["head detection"], ["single frame multi - person pose estimation"]], "incident_type": "material-method-metric-task"}, {"metric": [["AP evaluation measure"], ["AP"], ["accuracy"]], "material": [["WAF datasets"], ["MPII Human Pose"], ["WAF"], ["MPII Multi - Person dataset"], ["MPII Human Pose dataset"], ["MPII Video Pose \u201d dataset"], ["AP"]], "task": [["pose estimation"], ["ArtTrack"], ["single - frame pose estimation"], ["graph partitioning"], ["head detection"], ["single frame multi - person pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}, {"task": [["single - frame pose estimation"]], "incident_type": "material-method-metric-task"}]}
{"33261d252218007147a71e40f8367ed152fa2fe0": [{"task": [["prediction"], ["plain string matching"], ["validation"], ["Question Answering"]], "material": [["QA"], ["WebQuestions"], ["open QA"]], "metric": [["F1 score"]], "method": [["WebQuestions"]], "incident_type": "material-method-metric-task"}, {"task": [["Question Answering"]], "incident_type": "material-method-metric-task"}]}
{"3448e6a5039417dc1ae890efeca3bef5390ace7c": [{"task": [["high - order feature interactions"], ["model evaluation"], ["Knowledge Discovery"]], "method": [["CIN"]], "metric": [["accuracy"]], "material": [["Bing News dataset"], ["Bing News Dataset"], ["CIN"]], "incident_type": "material-method-metric-task"}]}
{"35734e8724559fb0d494e5cba6a28ad7a3d5dd4d": [{"metric": [["test set error rate"], ["classification accuracy"], ["error rate"], ["test set error"], ["worst case error"], ["per - step success rate"], ["accuracy"]], "method": [["CIFAR - 10"]], "task": [["generating adversarial examples"], ["classification"]], "material": [["MNIST"], ["MNIST LeCun + 98 test set"], ["AI"], ["CIFAR - 10"], ["MNIST dataset"]], "incident_type": "material-method-metric-task"}]}
{"364c1a3df58d87cb40ab33fdf3831cf2862f3570": [{"material": [["aNMM - 2"], ["MAP"], ["aNNM - 2"], ["aNNM - 1"], ["aNMM - 1"], ["TRAIN"], ["TREC QA data"], ["TRAIN - ALL"], ["ARC - I"]], "metric": [["MAP"], ["ranking score"], ["aNMM score"], ["accuracy"]], "task": [["question / answer matching"], ["answer sentence selection task"], ["aNMM"], ["Question answering"], ["answer re - ranking"], ["question / answer matching problem"], ["answer passage re - ranking task"], ["answer sentence retrieval"], ["question answering"], ["RQ1"], ["RQ2"], ["ranking answers"], ["Ranking Short Answer Texts"]], "method": [["aNMM - 2"], ["ARC - I"], ["ARC - II"]], "incident_type": "material-method-metric-task"}, {"task": [["question / answer matching"]], "incident_type": "material-method-metric-task"}]}
{"3842ee1e0fdfeff936b5c49973ff21adfaaf3929": [{"task": [["digit classification"], ["image classification"], ["classification"], ["generative tasks"]], "method": [["ADDA"]], "material": [["NYU"], ["MNIST"], ["NYUD dataset"], ["USPS"], ["ImageNet"], ["ADDA"], ["MNIST USPS"], ["USPS MNIST"]], "metric": [["average accuracy"], ["USPS"], ["accuracy"]], "incident_type": "material-method-metric-task"}]}
{"38cc89399dd6f5aaab1654f27ab3c9eeade12a36": [{"metric": [["error"], ["competitive accuracy"], ["lower bound error"], ["average error"], ["accuracy"]], "task": [["3D human pose estimation"], ["3D pose estimation"], ["detections"], ["3D pose"], ["human action or activity recognition"], ["real - time scenarios"], ["2D pose estimation"], ["human 3D pose estimation"], ["2D pose estimator"], ["3D pose estimate"]], "material": [["Human3.6 M dataset"], ["Human 3.6 M dataset"], ["HumanEva"], ["HumanEva dataset"], ["MPII dataset"]], "incident_type": "material-method-metric-task"}]}
{"38e2f851b705faa0d0a698ed9885bd6834440073": [{"method": [["MAML"], ["PLATIPUS"], ["Probabilistic Model - Agnostic Meta - Learning"]], "material": [["MAP"], ["- shot"], ["PLATIPUS"], ["MAP approximation"], ["SNAIL"], ["MAP inference"]], "task": [["Ambiguous image classification"], ["few - shot learning"], ["5 - shot regression"], ["few - shot medical image classification"], ["- shot image classification"], ["few - shot learning problem"], ["few - shot task"], ["celebA attribute classification task"]], "metric": [["accuracy score"], ["coverage score"], ["Accuracy"], ["accuracy"]], "incident_type": "material-method-metric-task"}]}
{"3aa21de1a7c97e0458e10ed5730ce160bb436caa": [{"method": [["Pixel2Mesh"], ["G - ResNet"], ["3D - R2N2"]], "metric": [["accuracy"], ["F - score"], ["testing error"], ["mean F - score"], ["mean score"], ["F - Score"]], "task": [["3D reconstruction"], ["mesh representation"], ["multi - view reconstruction"], ["large - scale high - quality reconstruction"], ["single image reconstruction"], ["shape analysis"]], "material": [["3D - R2N2"], ["Online Products dataset"], ["G - ResNet block"]], "incident_type": "material-method-metric-task"}]}
{"3acc07f7f8951617276cf99483ed02aeb0a6eeac": [{"material": [["SYNTHIA - RAND - CITYSCAPES"], ["synthetic SYNTHIA dataset"], ["SYNTHIA dataset"], ["SYNTHIA datasets"], ["Cityscapes dataset"], ["real Cityscapes dataset"], ["FCN - 8s"], ["SYNTHIA"], ["Cityscapes"]], "task": [["automatic semantic segmentation"], ["structured prediction"], ["semantic image segmentation of urban scenes"], ["semantic segmentation"], ["segmentation"], ["Semantic Segmentation of Urban Scenes"], ["classification"], ["superpixel classification - based segmentation"]], "method": [["SYNTHIA"]], "metric": [["accuracy"]], "incident_type": "material-method-metric-task"}, {"task": [["semantic segmentation"], ["segmentation"]], "incident_type": "material-method-metric-task"}]}
{"3ca3993b1f3536b15112f759067f62e999c5d38f": [{"material": [["T - LESS dataset"], ["T - LESS"], ["LINEMOD Dataset"], ["LINEMOD dataset"]], "task": [["pose estimation"], ["3D pose estimation of object instances"], ["3D detection"], ["3D pose estimation"], ["2D detection"], ["detection"], ["pose prediction"], ["segmentation"], ["segmentations"], ["object segmentation"], ["3D object detection"], ["pose estimate"], ["hand detection"]], "metric": [["error"], ["accuracy"]], "method": [["T - LESS"], ["T - LESS Dataset"]], "incident_type": "material-method-metric-task"}]}
{"3cf31ecb2724b5088783d7c96a5fc0d5604cbf41": [{"material": [["Penn Chinese Treebank 5.1"], ["English"], ["Chinese"], ["UAS"]], "metric": [["unlabeled accuracy"], ["UAS accuracy"], ["UAS"], ["accuracy"]], "method": [["BiLSTM"]], "task": [["parsing"], ["dependency parsing"], ["transition scoring"]], "incident_type": "material-method-metric-task"}]}
{"3daa086acd367dc971a2dc1382caba2031294233": [{"task": [["human segmentation"], ["object detector"], ["semantic part segmentation"], ["instance segmentation"], ["part - level instance segmentation"], ["human instance segmentation"], ["instance - level part segmentation"], ["detection"], ["segmentation"], ["semantic segmentation"], ["object detectors"], ["human instance - segmentation"], ["instancelevel segmentation"], ["instance - level segmentation"]], "material": [["VOC 2011"], ["Fashionista"], ["Pascal dataset"], ["Pascal Person - Part dataset"], ["MS - COCO"], ["Pascal VOC dataset"], ["VOC 2012"], ["VOC 2012 validation set"], ["Pascal Person - Parts dataset"], ["Pascal Person - Parts Dataset"], ["Pascal VOC"]], "metric": [["AP r thresholds"], ["AP r"], ["AP r vol"], ["r score"], ["accuracy gap"], ["IoU"], ["AP r metric"], ["AP metric"], ["AP"]], "method": [["Deeplab - v2"]], "incident_type": "material-method-metric-task"}]}
{"408e8eecc14c5cc60bbdfc486ba7a7fc97031788": [{"task": [["Classification"], ["image restoration"], ["image classification"], ["image classification tasks"], ["classification"], ["visual object recognition"]], "material": [["Caltech - 101"], ["PASCAL VOC dataset"], ["CIFAR - 10"], ["STL - 10"], ["STL - 10 test set"]], "metric": [["average accuracy"], ["classification error"], ["HOG baseline"], ["classification accuracy"], ["average per - class accuracy"], ["average overall accuracy"], ["accuracy"]], "method": [["STL - 10"]], "incident_type": "material-method-metric-task"}, {"metric": [["accuracy"]], "task": [["image classification"], ["classification"]], "incident_type": "material-method-metric-task"}]}
{"4365eb43a635bc6431dfaf3af1f7bf7bf55522cc": [{"task": [["single model detector"], ["robust object detection"], ["object detection"], ["object category prediction"], ["accurate object detection"], ["detection"], ["specific object detection"], ["image classification"], ["single branch detectors"], ["detectors"], ["pedestrian and car detection"], ["fingerprint recognition"], ["General object detection"], ["robust detection"], ["Object Detection"]], "method": [["Faster R - CNN"], ["Fast / Faster R - CNN"], ["Gu"], ["CoupleNet"]], "metric": [["accuracy"], ["low confidence score"], ["AP"], ["score gap"], ["mAP"]], "material": [["PASCAL VOC 07 / 12"], ["VOC2012 dataset"], ["VOC 2007 trainval"], ["VOC dataset"], ["MS COCO"], ["COCO datasets"], ["VOC07"], ["VOC2007"], ["COCO"], ["VOC 2012 trainval"], ["PASCAL VOC2007"], ["VOC2012"], ["VOC 2012 test set"], ["VOC2012 test set"], ["VOC12"], ["PASCAL VOC 2007"], ["VOC 2007 test set"]], "incident_type": "material-method-metric-task"}]}
{"436b07bebaa1d1f05ef85415e10374048d25334d": [{"task": [["translation"], ["machine translation"]], "method": [["SPARSELY - GATED MIXTURE - OF - EXPERTS LAYER"]], "metric": [["BLEU score"], ["tokenized BLEU score"]], "material": [["BILLION WORD GOOGLE NEWS CORPUS"], ["English \u2192 Korean"], ["WMT'14"]], "incident_type": "material-method-metric-task"}]}
{"44078d0daed8b13114cffb15b368acc467f96351": [{"material": [["VGG - Face dataset"], ["CELEB - 1000 dataset"], ["LFW datasets"], ["CFP datasets"], ["CASIA - WebFace dataset"], ["CFP dataset"], ["IJB - A datasets"], ["IJB - A"], ["IJB - A dataset"]], "metric": [["F - score"], ["table - score"], ["cosine similarity score"], ["- score"], ["False Non - Match Rate"], ["error rate"], ["accuracy"]], "task": [["verification"], ["identification"], ["face verification"], ["Face Verification"], ["face detection"], ["multiclass classification"], ["convergence"]], "method": [["IJB - A"], ["IJB - A dataset"]], "incident_type": "material-method-metric-task"}]}
{"45429c281e30f9e87ebcd1ae42e0656d2ead24d1": [{"task": [["image super - resolution"], ["Image - to - image translation"], ["deep image synthesis"], ["semantic manipulation"], ["Semantic Manipulation"], ["High - Resolution Image Synthesis"], ["high - resolution image generation tasks"], ["image synthesis"], ["editing"], ["image - to - image translation"], ["Photo - realistic image rendering"], ["high - resolution images"], ["image synthesis task"], ["image - to - image tasks"]], "material": [["NYU Indoor RGBD dataset"], ["Cityscapes validation set"], ["NYU dataset"], ["ADE20"], ["Cityscapes dataset"], ["ADE20 K dataset"], ["C64 - C128 - C256 - C512"]], "metric": [["segmentation accuracy"], ["pixel - wise accuracy"]], "incident_type": "material-method-metric-task"}]}
{"455da02e5048dffb51fb6ab5eb8aeca5926c9d9a": [{"method": [["AlexNet"], ["SPP - net"], ["DET"], ["Spatial Pyramid Pooling"], ["R - CNN"], ["SPP"]], "metric": [["accuracy"], ["error"], ["top - 1 error rates"], ["single - view testing accuracy"], ["top - 5 error"], ["Accuracy"], ["top - 1 error"], ["mAP"]], "material": [["Overfeat - 7"], ["Pascal VOC 2007"], ["Pascal VOC 2007 dataset"], ["Caltech101 datasets"], ["ImageNet"], ["VOC 2007"], ["ZF - 5"], ["ImageNet 2012"], ["ImageNet 2012 dataset"], ["Caltech101"], ["mAP"]], "task": [["Visual Recognition"], ["SS"], ["recognition"], ["ImageNet Large Scale Visual Recognition Challenge"], ["object detection"], ["DET task"], ["detection"], ["Detection"], ["image classification"], ["Image Classification"], ["classification"], ["5 - scale version"], ["Object Detection"]], "incident_type": "material-method-metric-task"}]}
